<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <title>Improving Accessibility of Concept Bottleneck Layers for Scalable, Accurate, Interpretable Models</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:description" content="Improving Accessibility of Concept Bottleneck Layers for Scalable, Accurate, Interpretable Models"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="bootstrap-grid.css">
    <link rel="stylesheet" href="styles.css">
    <script type="text/javascript" src="../js/hidebib.js"></script>
    <script src="bootstrap.js"></script>
    <script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>


<div class="container">
    <div class="paper-title">
    <h1> 
        Improving Accessibility of Concept Bottleneck Layers for Scalable, Accurate, Interpretable Models
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                Gabriel Cha,
                Steven Luong,
                Mentor: Tsui-Wei (Lily) Weng
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span> {gcha, sxluong, lweng} @ucsd.edu </span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>HDSI Capstone 2025</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://github.com/gabrielchasukjin/cbm-gui-frontend/blob/main/report.pdf">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="https://github.com/gabrielchasukjin/cbm-gui-frontend">
                    <span class="material-icons"> code </span>
                    Code
                </a>
            </div>
        </div></div>
        <!--
        <div style="clear: both">
            <div class="example-btn-parent">
            <a class="example-btn" href="./examples.html">
                <span class="material-icons"> dashboard </span> 
                 Neuron Examples
            </a>
        </div></div>
        -->
    </div>
    

    
    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                Large Language Models (LLMs) have shown remarkable capabilities, but their <b>"black-box" nature</b> often makes them difficult to interpret. <b>Concept Bottle-neck Layers (CBLs)</b> address this by linking model outputs to human-understandable concepts. Our project introduces a <b>user-friendly Graphical User Interface (GUI)</b> that allows users, regardless of their technical background, to easily integrate CBLs into pre-trained LLMs (provided as .pt files), display top N highly activated concepts, and analyze and prune biased concepts. By identifying and unlearning biased concepts, these models can produce fairer, more reliable predictions. Our end goal is to provide users with the ability to scrutinize and adjust models to be <b>explainable and fair</b>. This work builds upon the research and framework developed by Weng et al. (2024).
            </p>
            <div style="text-align: center; margin: auto;">
                <left><p><b>Figure 1:</b> Visualization of Top 10 Concept Activation during Classification Task.</p></left>
                <center><img class="card-img-top" src="bar-chart.png" style="width:650px"></center>
            </div>
        </div>
    </section>

    <section id="motivation"/>
        <hr>
        <h2>Motivation</h2>
        <div class="flex-row">
            <p>
                Large Language Models (LLMs) excel in various tasks but often lack transparency. <b>Concept bottleneck layers (CBLs)</b> allow for transparency by connecting model outputs to human-readable concepts. However, existing CBL implementations require technical expertise, restricting their accessibility. Our project builds on Weng et al. (2024) to create an easy-to-use GUI, allowing users of all skill levels to visualize concept activations, adjust weights, and unlearn biased concepts for greater interpretability, trustworthiness, and fairness.<br><br>

                <b>Key Challenges:</b>
                <ul>
                    <li><b>Technical Barrier:</b> Current CBL tools require programming expertise, limiting their use to technical users</li>
                    <li><b>Lack of Visualization:</b> Existing implementations don't provide intuitive ways to visualize and understand concept activations</li>
                    <li><b>Limited Control:</b> Users need better tools to identify and mitigate biased concepts in their models</li>
                </ul>
            </p>
        </div>
    </section>

    <section id="method"/>
        <hr>
        <h2>Method</h2>
        <div class="flex-row">
            <p>
                <h3>User Interface Workflow</h3>
                Our GUI makes CBL technology accessible to all users by providing:
                <ul>
                    <li>Easy integration of CBLs into pre-trained models</li>
                    <li>Interactive visualization of concept activations</li>
                    <li>Tools for identifying and mitigating biased concepts</li>
                </ul>
                <br>
                The workflow consists of four simple steps:
                
                <h4>Step 1: Train</h4>
                Users can easily train a CBL layer by uploading their pre-trained model and clicking the "Train" button. The interface provides real-time training progress and allows configuration of key parameters through an intuitive form. Our training process, developed and inspired by Weng et al. (2024), involves several sophisticated steps that work together to create interpretable concept representations.

                <details>
                    <summary>Technical Training Details</summary>
                    <div>
                        <ol>
                            <li><b>Concept Generation:</b> Given a text classification task, generate a concept set for each class by prompting modern language models. This involves using GPT-based models to extract relevant concepts that characterize each class.</li>
                            <li><b>Automatic concept scoring (ACS):</b> Leverage sentence embedding models to measure the similarity between each concept in the concept set and each text sample in the dataset. We use state-of-the-art embedding models to create dense vector representations for both concepts and text samples.</li>
                            <li><b>Train the Concept Bottleneck Layer:</b> Learn the concept mapping from uninterpretable features to human-interpretable concepts by maximizing the similarity between the neuron activations and the concept scores. This involves optimizing a neural network layer that transforms raw model features into concept-aligned representations.</li>
                            <li><b>Learn the predictor:</b> Train the final linear layer to make predictions for the downstream tasks. This layer learns to combine concept activations to make accurate predictions while maintaining interpretability.</li>
                        </ol>
                    </div>
                </details>

                <h4>Step 2: Classify</h4>
                After training, users can input text for classification. The model processes the input and provides predictions while exposing the underlying concept activations.

                <h4>Step 3: Visualize</h4>
                The GUI presents interactive visualizations of concept activations, helping users understand which concepts contributed most to the model's decision. Users can explore concept relationships and their impact on classifications.

                <h4>Step 4: Prune</h4>
                Based on the visualizations, users can identify and prune unwanted or biased concepts. The interface provides tools to adjust concept weights and observe the immediate impact on model predictions.
                <br><br>

                <div style="text-align: center; margin: auto;">
                    <left><p><b>Figure 2:</b> CBM-GUI Interface: Our user-friendly interface showing the classification task with real-time concept visualization.</p></left>
                    <center><img class="card-img-top" src="Classy.png" style="width:850px; border: 1px solid #ddd; border-radius: 5px;"></center>
                </div>
                <br><br>

                <h3>Technical Deep Dive</h3>
                <p>
                    Our system architecture is designed for efficiency and scalability, combining modern web technologies with robust database management.
                </p>

                <details>
                    <summary>Technical Implementation Details</summary>
                    <div>
                        <h4>Tech Stack</h4>
                        The CBM-GUI utilizes a Django-React structure:
                        <ul>
                            <li><b>Frontend:</b> React handles dynamic UI, user interactions, and state management</li>
                            <li><b>Backend:</b> Django processes API requests, manages model training scripts, and interacts with the database</li>
                            <li><b>Microservices:</b> Each microservice performs specific tasks, such as running model training scripts and handling post-processing</li>
                            <li><b>Database:</b> SQLite3 stores trained models, allowing users to switch between them and restore previous configurations</li>
                        </ul>
                        When a user interacts with the GUI, React sends API requests to Django, which calls the appropriate microservice. The backend then retrieves or updates stored models, allowing real-time training updates and result visualization.

                        <h4>Database and Model Management</h4>
                        The system integrates an SQLite3 database to manage trained models. This enables:
                        <ul>
                            <li>Users to train multiple models in separate tabs</li>
                            <li>Storage of trained models for future retrieval and comparison</li>
                            <li>Easy switching between models without retraining from scratch</li>
                        </ul>
                        Users can restore past models, facilitating iterative experimentation and performance evaluation. Each model entry in the database includes metadata such as training parameters, dataset used, and timestamps.
                    </div>
                </details>
            </p>
        </div>
    </section>

    <section id="results"/>
        <hr>
        <h2>Experiment Results</h2>
        <div class="flex-row">
            <div class="mx-auto">
                <p><b>[Section Under Construction]</b></p>
                <p>
                    Our pruning interface allows users to selectively remove concepts from their trained CBL models. Through our intuitive GUI, users can:
                    <ul>
                        <li>Select specific concepts they wish to remove from the model</li>
                        <li>Apply pruning with a single click</li>
                        <li>View immediate feedback on model performance</li>
                    </ul>
                </p>

                <div style="text-align: center; margin: auto;">
                    <left><p><b>Figure 3:</b> Pruning Interface: Users can select and remove unwanted concepts while monitoring model performance.</p></left>
                    <center><img class="card-img-top" src="Prune.png" style="width:850px; border: 1px solid #ddd; border-radius: 5px;"></center>
                </div>
                <br>

                <h3>Impact on Model Performance</h3>
                <p>
                    One of the key metrics we track is the model's validation accuracy before and after pruning. Interestingly, maintaining similar accuracy post-pruning is often desirable, as it indicates that:
                    <ul>
                        <li>The removed concepts were potentially redundant or not critical for the core task</li>
                        <li>The model has found alternative, potentially more appropriate concepts to rely on</li>
                        <li>We've successfully removed unwanted biases without compromising model performance</li>
                    </ul>
                    
                    This stability in accuracy suggests that our pruning method effectively removes targeted concepts while preserving the model's overall predictive capabilities. It demonstrates that we can make models more interpretable and fair without sacrificing their performance.
                </p>
            </div>
        </div>
    </section>


    <section>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
        <center><p><a href='https://accessibility.ucsd.edu/'><b>Accessibility</b></a></p></center>
    </section>
    


</div>
</body>
</html>
